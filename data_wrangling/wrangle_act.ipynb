{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle and Analyze Data\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#1.-Gathering\">Gathering</a></li>\n",
    "<li><a href=\"#2.-Assessing\">Assessing</a></li>\n",
    "<li><a href=\"#3.-Cleaning\">Cleaning</a></li>\n",
    "<li><a href=\"#4.-Analysis\">Analysis</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `twitter-archive-enhanced.csv` has been provided. We will need to download the file image-predictions.tsv and generate a tweet-json.txt connecting to the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the request library to download image_predictions.tsv\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "r = requests.get(url)\n",
    "\n",
    "with open('./image-predictions.tsv', 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "# Retrieve HTTP meta-data\n",
    "print(r.status_code)\n",
    "print(r.headers['content-type'])\n",
    "print(r.encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get favorite and retweet count from Twitter API\n",
    "#import tweepy\n",
    "#from tweepy import OAuthHandler\n",
    "#import json\n",
    "#from timeit import default_timer as timer\n",
    "\n",
    "#consumer_key = '-'\n",
    "#consumer_secret = '-'\n",
    "#access_token = '-'\n",
    "#access_secret = '-'\n",
    "\n",
    "#auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_token, access_secret)\n",
    "#api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "\n",
    "# Vars\n",
    "#df_1 = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "#tweet_ids = df_1.tweet_id.values\n",
    "#fails_dict = {}\n",
    "#count = 0\n",
    "\n",
    "#start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "#with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "#    for tweet_id in tweet_ids:\n",
    "#        count += 1\n",
    "#        print(str(count) + \": \" + str(tweet_id))\n",
    "#        try:\n",
    "#            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "#            print(\"Success\")\n",
    "#            json.dump(tweet._json, outfile)\n",
    "#            outfile.write('\\n')\n",
    "#        except tweepy.TweepError as e:\n",
    "#            print(\"Fail\")\n",
    "#            fails_dict[tweet_id] = e\n",
    "#            pass\n",
    "#end = timer()\n",
    "#print(end - start)\n",
    "#print(fails_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the files downloaded, the next step will be assessing the data looking for Quality and Tidy issues. \n",
    "\n",
    "## 1.1 Create one dataframe from each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "df_image_predictions = pd.read_csv('image-predictions.tsv', sep='\\t')\n",
    "df_tweet_json = pd.read_json('tweet-json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Assess Twitter Archive Enhanced Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_archive.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_twitter_archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for replies & retweets\n",
    "print('Number of replies:', df_twitter_archive.in_reply_to_user_id.count())\n",
    "print('Number of retweets:', df_twitter_archive.retweeted_status_id.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_archive.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_archive.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_archive.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_archive.query('name == \"a\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_archive.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Assess Image Predictions Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There seems to be some inconsistency with the capitalization of the p1, p2 and p3 columns\n",
    "df_image_predictions.p1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there tweets with duplicated images?\n",
    "df_image_predictions.jpg_url.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions[df_image_predictions.jpg_url.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check one of these tweets with duplicated image url\n",
    "df_image_predictions.query('jpg_url == \"https://pbs.twimg.com/media/CtVAvX-WIAAcGTf.jpg\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check both tweets in the archive dataframe\n",
    "df_twitter_archive.query('tweet_id == 780601303617732608')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_archive.query('tweet_id == 821813639212650496')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that the duplicated images corresponds with the retweets, that we should clean in the clean step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_predictions.tweet_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Assess Tweet Json Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_tweet_json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_json.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the max favorite_count diverges a lot from the mean, let´s check if it could be a error\n",
    "df_tweet_json.favorite_count.sort_values(ascending=False)\n",
    "\n",
    "# Looking at the results, it doesn´t seem so. There are at least 6 tweets with over 100k favorites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let´s do the same with retweet count\n",
    "df_tweet_json.retweet_count.sort_values(ascending=False)\n",
    "\n",
    "# Again, these results seem normal, so no apparent input/import errors here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values on fav and retweet count\n",
    "print('Null values in favorite_count?', df_tweet_json.favorite_count.isnull().any())\n",
    "print('Null values in retweet_count?', df_tweet_json.retweet_count.isnull().any())\n",
    "print('Null values in user?', df_tweet_json.user.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Issues \n",
    "\n",
    "### Quality issues assesed\n",
    "\n",
    "1. `tweet_id` is an integer but it should be a string as it is not used to compute anything\n",
    "2. `timestamp` column should have datetime format\n",
    "3. There are replies and retweets in our data\n",
    "4. There are tweets without images\n",
    "5. `name` column contains strings that aren´t names as 'a', 'an', 'the'...\n",
    "6. `source` column contains html code\n",
    "7. `p1`, `p2`, `p3` columns have inconsistent capitalization\n",
    "8. Not all dogs have been properly matched to a particular breed in columns\n",
    "9. There are too many unneded columns\n",
    "\n",
    "### Tidyness\n",
    "\n",
    "1. One of the rules of Tiny Data is that each variable forms a column. In this dataframe we have one variable `dog_stages` split in 4 columns `doggo`, `floofer`, `pupper`, `puppo`.\n",
    "2. Another rule about Tiny Data is that each type of obserbational unit forms a table. We are analyzing tweets, but we have the information split in three different dataframes. We should combine them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let´s creat copies of our dataframes\n",
    "df2_twitter_archive = df_twitter_archive.copy()\n",
    "df2_image_predictions = df_image_predictions.copy()\n",
    "df2_tweet_json = df_tweet_json.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Tidiness issues\n",
    "\n",
    "Let´s with the tidyness issues detected in our assessment phase. To solve the detected problem we will do the next actions:\n",
    "\n",
    "1. Create one dog_stage column from 4 different ones\n",
    "2. Combine DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Create one dog_stage column from 4 different ones\n",
    "\n",
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the dataframe & create the dog_stage column\n",
    "dog_stage = []\n",
    "\n",
    "for index, row in df2_twitter_archive.iterrows():\n",
    "    if row['doggo'] == 'doggo': dog_stage.append('doggo')\n",
    "    elif row['floofer'] == 'floofer': dog_stage.append('floofer')\n",
    "    elif row['pupper'] == 'pupper': dog_stage.append('pupper')\n",
    "    elif row['puppo'] == 'puppo': dog_stage.append('puppo')\n",
    "    else: dog_stage.append('None')\n",
    "\n",
    "df2_twitter_archive['dog_stage'] = dog_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete old columns\n",
    "df2_twitter_archive.drop(['doggo', 'floofer', 'pupper', 'puppo'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_twitter_archive.dog_stage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Combine DataFrames\n",
    "\n",
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the json dataframe contains a lot of columns we are not interested in. \n",
    "# Let´s create another one keeping only the columns we are interested in.\n",
    "df2_tweet_json = df2_tweet_json[['id', 'favorite_count', 'retweet_count']]\n",
    "\n",
    "# Rename id column to tweet_id to ease the later merge\n",
    "df2_tweet_json.rename(columns={'id' : 'tweet_id'}, inplace=True)\n",
    "\n",
    "df2_tweet_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all dataframes so we have all the information related to a tweet in the same one \n",
    "aux = pd.merge(df2_twitter_archive, \n",
    "                 df2_tweet_json,\n",
    "                 left_on='tweet_id',\n",
    "                 right_on='tweet_id',\n",
    "                 how='left')\n",
    "\n",
    "df_merged_dataframes = pd.merge(aux,\n",
    "                               df2_image_predictions,\n",
    "                               left_on='tweet_id',\n",
    "                               right_on='tweet_id',\n",
    "                               how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we have a single dataframe with all the columns from the 3 previous ones\n",
    "df_merged_dataframes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Quality Issues\n",
    "\n",
    "Next, we´ll fix the quality issues raised during our assessment with the following actions:\n",
    "\n",
    "1. Convert tweet_id from integer to string\n",
    "2. Apply datetime format to timestamp column\n",
    "3. Delete replies and retweets\n",
    "4. Delete tweets without image\n",
    "5. Fix wrong names\n",
    "6. Strip html tags from source column\n",
    "7. Fix inconsistent capitalization in `p1`, `p2`, `p3` colums\n",
    "8. Create one `breed` column\n",
    "9. Delete unneded columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Convert tweet_id from integer to string\n",
    "\n",
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column type\n",
    "df_merged_dataframes.tweet_id = df_merged_dataframes.tweet_id.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_string_dtype\n",
    "is_string_dtype(df_merged_dataframes.tweet_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Apply datetime format to timestamp column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_dataframes.timestamp = pd.to_datetime(df_merged_dataframes.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "is_datetime64_any_dtype(df_merged_dataframes.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Delete replies and retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete tweets that are replies from the dataframe\n",
    "df_merged_dataframes = df_merged_dataframes[df_merged_dataframes.in_reply_to_status_id.isnull()] \n",
    "\n",
    "# Delete tweets that are retweets from the dataframe\n",
    "df_merged_dataframes = df_merged_dataframes[df_merged_dataframes.retweeted_status_id.isnull()] # 181 results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for replies & retweets\n",
    "print('Number of replies:', df_merged_dataframes.in_reply_to_user_id.count())\n",
    "print('Number of retweets:', df_merged_dataframes.retweeted_status_id.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Delete tweets without image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_dataframes = df_merged_dataframes[df_merged_dataframes.jpg_url.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_dataframes.jpg_url.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 Fix wrong names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are names that are not names as 'a', 'an', 'the' that seem clear input errors.\n",
    "# Let´s clean them converting all lowercase word to 'None'\n",
    "df_merged_dataframes.name = df_merged_dataframes.name.mask(df_merged_dataframes.name.str.match(r'^[a-z]+$'), 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_dataframes.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6 Strip html tags from source column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df_merged_dataframes.source = df_merged_dataframes.source.apply(lambda x: re.sub('<[^<]+?>', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_dataframes.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.7 Fix inconsistent capitalization in p1, p2, p3 colums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase each value in those columns\n",
    "for _ in ['p1', 'p2', 'p3']:\n",
    "  df_merged_dataframes[_] = df_merged_dataframes[_].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check visually that everything is lowercase\n",
    "df_merged_dataframes.p1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.8 Create one breed column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our dataframe, our dogs are categorized in the p1, p2, p3 columns, but not all of them\n",
    "# have been positively matched with a particular breed. In this cell we are going to create\n",
    "# a new column breed with the breed when we have it validated and 'None' in any other case.\n",
    "breed = []\n",
    "\n",
    "for index, row in df_merged_dataframes.iterrows():\n",
    "    if row['p1_dog'] == True:\n",
    "        breed.append(row['p1'])\n",
    "    elif row['p2_dog'] == True:\n",
    "        breed.append(row['p2'])\n",
    "    elif row['p3_dog'] == True:\n",
    "        breed.append(row['p3'])\n",
    "    else:\n",
    "        breed.append('None')\n",
    "\n",
    "df_merged_dataframes['breed'] = breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let´s drop all the dogs that haven´t been properly categorized\n",
    "df_merged_dataframes = df_merged_dataframes.query('breed != \"None\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_dataframes.breed.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.9 Delete unneded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are columns without data that we are not going to use\n",
    "df_merged_dataframes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneded columns\n",
    "df_merged_dataframes.drop(columns=['in_reply_to_status_id', 'in_reply_to_user_id', \\\n",
    "                                   'retweeted_status_id', 'retweeted_status_user_id',\\\n",
    "                                   'retweeted_status_timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_dataframes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's save the dataframe to a csv file\n",
    "df_merged_dataframes.to_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final phase of the project, we will answer some questions around the data we´ve been gathering, assessing and cleaning. \n",
    "\n",
    "**Questions**\n",
    "\n",
    "1. Which are our most favorited dogs?\n",
    "2. Which are our most retweeted dogs?\n",
    "3. Is there any correlation between favorite_count and retweet_count?\n",
    "4. Is there any correlation between the number of pictures and the favorites_count?\n",
    "4. Which is the most favorited dog breed?\n",
    "5. Which breeds receive more favorites in average?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Let´s see the most favorited dogs\n",
    "\n",
    "No very useful, but after so many work with the data I´m curious about how look the most popular dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_favorited_dogs = df_merged_dataframes.sort_values(by='favorite_count', ascending=False).head(5).jpg_url\n",
    "\n",
    "for dog_url in top5_favorited_dogs:\n",
    "    response = requests.get(dog_url, stream=True)\n",
    "    img = Image.open(response.raw)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Let´s see the most retweeted dogs\n",
    "\n",
    "Again, not very useful. Our expectation is to see some of the most favorited dogs also in this short list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_retweeted_dogs = df_merged_dataframes.sort_values(by='retweet_count', ascending=False).head(5).jpg_url\n",
    "\n",
    "for dog_url in top5_retweeted_dogs:\n",
    "    response = requests.get(dog_url, stream=True)\n",
    "    img = Image.open(response.raw)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Is there any correlation between favorite_count and retweet_count?\n",
    "\n",
    "As we´ve seen with our top 5, we expect that the correlation will be positive between both characteristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "chart_title=\"Correlation favorite_count / retweet_count\"\n",
    "chart_xlabel=\"favorite count\"\n",
    "chart_ylabel=\"retweet count\"\n",
    "\n",
    "# Plot\n",
    "ax = plt.subplots(figsize=(16,9))\n",
    "ax = sns.regplot(x=df_merged_dataframes['favorite_count'], y=df_merged_dataframes['retweet_count'])\n",
    "\n",
    "# Function that we will use during the exercise to decorate our charts\n",
    "# This function was creatd in the first module of the Data Analyst Nanodegree\n",
    "def decorate(title, xlabel, ylabel, xticks=None, xticklabels=None, yticks=None, yticklabels=None):\n",
    "    ax.set_title(title, fontsize=22)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)  \n",
    "    if xticks is not None:\n",
    "        ax.set_xticks(xticks)\n",
    "    if xticklabels is not None:\n",
    "        ax.set_xticklabels(xticklabels, rotation=70)\n",
    "    if yticks is not None:\n",
    "        ax.set_xticks(yticks)\n",
    "    if yticklabels is not None:\n",
    "        ax.set_xticklabels(yticklabels, rotation=70)\n",
    "    ax.grid(alpha=1)\n",
    "    sns.set(style=\"dark\")\n",
    "\n",
    "# Decorate\n",
    "decorate(chart_title, chart_xlabel, chart_ylabel)\n",
    "\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we were expecting, the correlation between favorite_count and retweet_count is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Is there any correlation between the number of pictures and the favorites_count?\n",
    "\n",
    "Maybe tweets with more than 1 picture receive more favorites than tweets with only one image. Let´s check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "chart_title=\"Correlation number of pictures / favorite_count\"\n",
    "chart_xlabel=\"Number of pictures\"\n",
    "chart_ylabel=\"Favorites count\"\n",
    "\n",
    "# Plot\n",
    "ax = plt.subplots(figsize=(16,9))\n",
    "ax = sns.regplot(x=df_merged_dataframes['img_num'], y=df_merged_dataframes['favorite_count'])\n",
    "\n",
    "# Decorate\n",
    "decorate(chart_title, chart_xlabel, chart_ylabel)\n",
    "\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can appreciate a weak positive correlation between the number of pictures and the favorites count obtained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Which is the most favorited dog breed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a group breed / favorite count\n",
    "grp = pd.DataFrame(df_merged_dataframes.groupby(['breed']).sum().favorite_count)\n",
    "\n",
    "# Create a dataframe with the top 10 breeds and their favorite_count\n",
    "df_favorite_breed = pd.DataFrame(grp.sort_values('favorite_count', ascending=False)).head(10)\n",
    "\n",
    "# Plot a graph\n",
    "# Variables\n",
    "chart_title=\"Most favorited breeds\"\n",
    "chart_xlabel=\"Breed\"\n",
    "chart_ylabel=\"Favorite Count\"\n",
    "chart_xticks=np.arange(len(df_favorite_breed))\n",
    "chart_xticklabels=df_favorite_breed.index\n",
    "\n",
    "# Plot a bar graph\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "ax.bar(chart_xticks, df_favorite_breed.favorite_count)\n",
    "\n",
    "# Decorate\n",
    "decorate(chart_title, chart_xlabel, chart_ylabel, chart_xticks, chart_xticklabels)\n",
    "\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Which breeds receive more favorites in average?\n",
    "\n",
    "The previous graph shows the most favorited breeds without having into account the number of samples of each dog. That could lead us to wrong conclusions, so now we are going to compute the popularity of dog breeds according to the number of favorites and the number of samples of each one in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the columns we need\n",
    "df_aux = pd.DataFrame(df_merged_dataframes.groupby(['breed']).sum().favorite_count)\n",
    "df_aux['breed_count'] = pd.DataFrame(df_merged_dataframes.groupby(['breed']).count().tweet_id)\n",
    "\n",
    "# Calculate the ration favorites / breed \n",
    "df_aux['favs_per_breed'] = df_aux['favorite_count'] / df_aux['breed_count']\n",
    "\n",
    "# Order the results\n",
    "df_aux = pd.DataFrame(df_aux.sort_values('favs_per_breed', ascending=False)).head(10)\n",
    "\n",
    "# Create a dataframe with the top 10 breeds and their favorite_count\n",
    "df_aux = pd.DataFrame(df_aux.sort_values('favs_per_breed', ascending=False)).head(10)\n",
    "\n",
    "# Plot a graph\n",
    "# Variables\n",
    "chart_title=\"Average favorites per breed\"\n",
    "chart_xlabel=\"Breed\"\n",
    "chart_ylabel=\"Favorite Count\"\n",
    "chart_xticks=np.arange(len(df_aux))\n",
    "chart_xticklabels=df_aux.index\n",
    "\n",
    "# Plot a bar graph\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "ax.bar(chart_xticks, df_aux.favs_per_breed)\n",
    "\n",
    "# Decorate\n",
    "decorate(chart_title, chart_xlabel, chart_ylabel, chart_xticks, chart_xticklabels)\n",
    "\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
